{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import os, sys, zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os: nt\n",
      "sys: 3.7.5 (default, Oct 31 2019, 15:18:51) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy: 1.17.4, C:\\Users\\UX490\\Anaconda3\\envs\\images\\lib\\site-packages\\numpy\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(\"os: %s\" % os.name)\n",
    "print(\"sys: %s\" % sys.version)\n",
    "print(\"numpy: %s, %s\" % (np.__version__, np.__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType='train2017'\n",
    "annFile=r'C:\\Users\\UX490\\Desktop\\coco\\annotations/instances_{}.json'.format(dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=28.19s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO categories: \n",
      "person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush\n",
      "\n",
      "COCO supercategories: \n",
      "furniture indoor accessory animal electronic person vehicle outdoor food appliance sports kitchen\n"
     ]
    }
   ],
   "source": [
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdogCats = coco.getCatIds(catNms=[\"hot dog\"]);\n",
    "hotdogIds = coco.getImgIds(catIds=hotdogCats);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(hotdogIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcats = [cat['name'] for cat in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIds = []\n",
    "\n",
    "for category in allcats:\n",
    "    Cats = coco.getCatIds(catNms=category)\n",
    "    Ids = coco.getImgIds(catIds=Cats)\n",
    "    for ids in Ids:\n",
    "        allIds.append(ids)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(allIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NohotdogIds = set(allIds)-set(hotdogIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115553"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(NohotdogIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "115553 + 1222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIds= set(allIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird = []\n",
    "for num in hotdogIds:\n",
    "    if num not in allIds:\n",
    "        weird.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX490\\Anaconda3\\envs\\images\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "imgIds = coco.getImgIds(imgIds = weird)\n",
    "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "I = io.imread(img['coco_url'])\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = set(hotdogIds) - set(weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115553"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NohotdogIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "no_hotdog = random.sample(NohotdogIds, 1222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_hotdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotdogIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog = hotdogIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgIds = coco.getImgIds(imgIds = hotdog)\n",
    "img = coco.loadImgs(imgIds[2])[0]\n",
    "I = io.imread(img['coco_url'])\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = I.reshape((1,) + I.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=r'C:\\Users\\UX490\\Desktop\\coco/preview', save_prefix='hotdog', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two issues. I need a train and validation set and secondly not \n",
    "# all pictures have the same size, looking at the pictures 480,640,3 \n",
    "# seems like a good shape as many pictures have that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 creating the train dataset. \n",
    "\n",
    "train_hotdog = random.sample(hotdog, 1000)\n",
    "train_no_hotdog = random.sample(no_hotdog, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 creating the validation dataset\n",
    "\n",
    "val_hotdog = list(set(hotdog) - set(train_hotdog))\n",
    "val_no_hotdog = list(set(no_hotdog) - set(train_no_hotdog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create the directories for train and val while resizing pictures if necessary\n",
    "\n",
    "# 1. First for train and hotdog\n",
    "new_width  = 640\n",
    "new_height = 480\n",
    "name = \"hotdog_\"\n",
    "imgIds = coco.getImgIds(imgIds = train_hotdog)\n",
    "num =0\n",
    "for i in range(0,len(train_hotdog)):\n",
    "    img = coco.loadImgs(imgIds[i])[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    pic=PIL.Image.fromarray(I, mode=None)\n",
    "    pic = pic.resize((new_width, new_height))\n",
    "    pic.save(os.path.join(r\"C:\\Users\\UX490\\Desktop\\coco\\Train\\hotdog\", name + str(num)) + '.JPG', 'JPEG', quality=90)\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train and no_hotdog\n",
    "\n",
    "name = \"no_hotdog_\"\n",
    "imgIds = coco.getImgIds(imgIds = train_no_hotdog)\n",
    "num =0\n",
    "for i in range(0,len(train_no_hotdog)):\n",
    "    img = coco.loadImgs(imgIds[i])[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    pic=PIL.Image.fromarray(I, mode=None)\n",
    "    pic = pic.resize((new_width, new_height))\n",
    "    pic.save(os.path.join(r\"C:\\Users\\UX490\\Desktop\\coco\\Train\\no_hotdog\", name + str(num)) + '.JPG', 'JPEG', quality=90)\n",
    "    num+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Val and hotdog\n",
    "\n",
    "name = \"val_hotdog_\"\n",
    "imgIds = coco.getImgIds(imgIds = val_hotdog)\n",
    "num =0\n",
    "for i in range(0,len(val_hotdog)):\n",
    "    img = coco.loadImgs(imgIds[i])[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    pic=PIL.Image.fromarray(I, mode=None)\n",
    "    pic = pic.resize((new_width, new_height))\n",
    "    pic.save(os.path.join(r\"C:\\Users\\UX490\\Desktop\\coco\\Val\\hotdog\", name + str(num)) + '.JPG', 'JPEG', quality=90)\n",
    "    num+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Val and no_hotdog\n",
    "\n",
    "name = \"val_no_hotdog_\"\n",
    "imgIds = coco.getImgIds(imgIds = val_no_hotdog)\n",
    "num =0\n",
    "for i in range(0,len(val_no_hotdog)):\n",
    "    img = coco.loadImgs(imgIds[i])[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    pic=PIL.Image.fromarray(I, mode=None)\n",
    "    pic = pic.resize((new_width, new_height))\n",
    "    pic.save(os.path.join(r\"C:\\Users\\UX490\\Desktop\\coco\\Val\\no_hotdog\", name + str(num)) + '.JPG', 'JPEG', quality=90)\n",
    "    num+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 444 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "125/125 [==============================] - 1279s 10s/step - loss: 0.7826 - accuracy: 0.6040 - val_loss: 0.6527 - val_accuracy: 0.6528\n",
      "Epoch 2/15\n",
      "125/125 [==============================] - 1903s 15s/step - loss: 0.6528 - accuracy: 0.6760 - val_loss: 0.5940 - val_accuracy: 0.7083\n",
      "Epoch 3/15\n",
      "125/125 [==============================] - 1396s 11s/step - loss: 0.5874 - accuracy: 0.7390 - val_loss: 0.5316 - val_accuracy: 0.7616\n",
      "Epoch 4/15\n",
      "125/125 [==============================] - 1579s 13s/step - loss: 0.5696 - accuracy: 0.7375 - val_loss: 0.5136 - val_accuracy: 0.7778\n",
      "Epoch 5/15\n",
      "125/125 [==============================] - 2255s 18s/step - loss: 0.5583 - accuracy: 0.7425 - val_loss: 0.6526 - val_accuracy: 0.7269\n",
      "Epoch 6/15\n",
      "125/125 [==============================] - 1586s 13s/step - loss: 0.5406 - accuracy: 0.7620 - val_loss: 0.5508 - val_accuracy: 0.7199\n",
      "Epoch 7/15\n",
      "125/125 [==============================] - 1904s 15s/step - loss: 0.5437 - accuracy: 0.7455 - val_loss: 0.5411 - val_accuracy: 0.7708\n",
      "Epoch 8/15\n",
      "125/125 [==============================] - 1133s 9s/step - loss: 0.5390 - accuracy: 0.7650 - val_loss: 0.5307 - val_accuracy: 0.7685\n",
      "Epoch 9/15\n",
      "125/125 [==============================] - 1113s 9s/step - loss: 0.5304 - accuracy: 0.7675 - val_loss: 0.5355 - val_accuracy: 0.7639\n",
      "Epoch 10/15\n",
      "125/125 [==============================] - 1088s 9s/step - loss: 0.5461 - accuracy: 0.7580 - val_loss: 0.4820 - val_accuracy: 0.7963\n",
      "Epoch 11/15\n",
      "125/125 [==============================] - 1081s 9s/step - loss: 0.5357 - accuracy: 0.7645 - val_loss: 0.5462 - val_accuracy: 0.7569\n",
      "Epoch 12/15\n",
      "125/125 [==============================] - 1086s 9s/step - loss: 0.5251 - accuracy: 0.7650 - val_loss: 0.5224 - val_accuracy: 0.7801\n",
      "Epoch 13/15\n",
      "125/125 [==============================] - 1057s 8s/step - loss: 0.5479 - accuracy: 0.7415 - val_loss: 0.5378 - val_accuracy: 0.7454\n",
      "Epoch 14/15\n",
      "125/125 [==============================] - 1067s 9s/step - loss: 0.5609 - accuracy: 0.7510 - val_loss: 0.5389 - val_accuracy: 0.7708\n",
      "Epoch 15/15\n",
      "125/125 [==============================] - 1062s 8s/step - loss: 0.5330 - accuracy: 0.7640 - val_loss: 0.5331 - val_accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "# so everything is ready to go. time to train the model\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 640, 480\n",
    "\n",
    "train_data_dir = r\"C:\\Users\\UX490\\Desktop\\coco/Train\"\n",
    "validation_data_dir = r\"C:\\Users\\UX490\\Desktop\\coco/Val\"\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 444\n",
    "epochs = 15\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the \n",
    "epochs1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "val_accuracy1 = [0.6528, 0.7083, 0.7616, 0.7778, 0.7269, 0.7199, 0.7708, 0.7685, 0.7639, 0.7963, 0.7569, 0.7801, 0.7454, 0.7708, 0.7662]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epochs1) == len(val_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"first_attempt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('first_try.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
